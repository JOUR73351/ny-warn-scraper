{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the import keyword to import pandas, requests, and bs4 modules\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the NY WARN notice url to a variable\n",
    "url = \"https://labor.ny.gov/app/warn/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define headers\n",
    "headers = {'accept-encoding': 'deflate'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a get request to the url using the requests library and assign the response to a variable called 'response'\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out status code of response to confirm that your request worked\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the response text using Beautiful Soup's html parser and assign output to a variable called 'soup'\n",
    "# response.text\n",
    "type(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the first table on the page and assign it to a variable called 'table'\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all rows from the table and assign to a variable called 'rows'\n",
    "table = soup.find(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the number of rows — this is how many WARN notices there were in 2020\n",
    "rows = soup.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1237"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layoff Date:  3/19/2020\n",
      "3/19/2020\n",
      "Layoff Date:  5/29/2020\n",
      "5/29/2020\n",
      "Layoff Date:  6/1/2020\n",
      "6/1/2020\n",
      "Layoff Date:  6/1/2020\n",
      "6/1/2020\n",
      "Layoff Date:  3/18/2020\n",
      "3/18/2020\n",
      "Layoff Date:  3/30/2020\n",
      "3/30/2020\n",
      "Layoff Date:  3/12/2020\n",
      "3/12/2020\n",
      "Layoff Date:  3/27/2020\n",
      "3/27/2020\n",
      "Layoff Date:  4/24/2020\n",
      "4/24/2020\n",
      "Layoff Date:  4/16/2020\n",
      "4/16/2020\n",
      "Layoff Date:  4/16/2020\n",
      "4/16/2020\n",
      "Layoff Date:  3/20/2020 (12); \n",
      "4/19/2020 (13)\n",
      "3/20/2020\n",
      "Layoff Date:  3/20/2020 (17); \n",
      "4/19/2020 (19)\n",
      "3/20/2020\n",
      "Layoff Date:  3/20/2020 (15); \n",
      "4/19/2020 (17)\n",
      "3/20/2020\n",
      "Layoff Date:  4/3/2020 (76);  \n",
      "4/24/2020 (9)\n",
      "4/3/2020\n",
      "Layoff Date:  3/20/2020\n",
      "3/20/2020\n",
      "Layoff Date:  6/30/2020\n",
      "6/30/2020\n",
      "Layoff Date:  4/23/2020\n",
      "4/23/2020\n",
      "Layoff Date:  3/16/2020\n",
      "3/16/2020\n",
      "Layoff Date:  3/16/2020\n",
      "3/16/2020\n",
      "Layoff Date:  3/16/2020\n",
      "3/16/2020\n",
      "Layoff Date:  3/16/2020\n",
      "3/16/2020\n",
      "Layoff Date:  3/16/2020\n",
      "3/16/2020\n",
      "Layoff Date:  3/16/2020\n",
      "3/16/2020\n",
      "Layoff Date:  3/16/2020\n",
      "3/16/2020\n",
      "Layoff Date:  3/16/2020\n",
      "3/16/2020\n",
      "Layoff Date:  3/17/2020\n",
      "3/17/2020\n",
      "Layoff Date:  4/4/2020\n",
      "4/4/2020\n",
      "Layoff Date:  3/30/2020\n",
      "3/30/2020\n",
      "Layoff Date:  3/30/2020\n",
      "3/30/2020\n",
      "Layoff Date:  4/4/2020\n",
      "4/4/2020\n",
      "Layoff Date:  4/4/2020\n",
      "4/4/2020\n",
      "Layoff Date:  4/4/2020\n",
      "4/4/2020\n",
      "Layoff Date:  4/4/2020\n",
      "4/4/2020\n",
      "Layoff Date:  4/4/2020\n",
      "4/4/2020\n",
      "Layoff Date:  4/4/2020\n",
      "4/4/2020\n",
      "Layoff Date:  4/4/2020\n",
      "4/4/2020\n",
      "Layoff Date:  4/4/2020\n",
      "4/4/2020\n",
      "Layoff Date:  4/4/2020\n",
      "4/4/2020\n",
      "Layoff Date:  4/8/2020\n",
      "4/8/2020\n",
      "Layoff Date:  4/22/2020\n",
      "4/22/2020\n",
      "Layoff Date:  3/19/2020\n",
      "3/19/2020\n",
      "Layoff Date:  3/17/2020\n",
      "3/17/2020\n",
      "Layoff Date:  3/24/2020\n",
      "3/24/2020\n",
      "Layoff Date:  4/13/2020\n",
      "4/13/2020\n",
      "Layoff Date:  4/13/2020\n",
      "4/13/2020\n",
      "Layoff Date:  4/10/2020 (115); \n",
      "4/27/2020 (18)\n",
      "4/10/2020\n",
      "Layoff Date:  4/13/2020\n",
      "4/13/2020\n",
      "Layoff Date:  3/27/2020\n",
      "3/27/2020\n",
      "Layoff Date:  3/27/2020\n",
      "3/27/2020\n",
      "Layoff Date:  4/13/2020\n",
      "4/13/2020\n",
      "Layoff Date:  4/16/2020 (1); \n",
      "4/24/2020 (1)\n",
      "4/16/2020\n",
      "Layoff Date:  Furloughs will occur on 4/4/2020.\n",
      "Furloughs\n",
      "Layoff Date:  4/3/2020\n",
      "4/3/2020\n",
      "Layoff Date:  3/22/2020 (111); \n",
      "4/17/2020 (8)\n",
      "3/22/2020\n",
      "Layoff Date:  3/23/2020 \n",
      "– Employees have been reinstated effective April 15, 2020.\n",
      "3/23/2020\n",
      "Layoff Date:  Separation of employees occurred on 3/22/2020 through 4/20/2020.\n",
      "Separation\n",
      "Layoff Date:  Separation of employees occurred on 3/22/2020 through 4/20/2020.\n",
      "Separation\n",
      "Layoff Date:  Separation of employees occurred on 3/22/2020 through 4/20/2020.\n",
      "Separation\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-7863dfab1143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# parse the response text and assign output to a variable called 'company_soup'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcompany_soup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# grab the first table on the page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ny-warn-scraper-49ZA02KO/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ny-warn-scraper-49ZA02KO/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ny-warn-scraper-49ZA02KO/lib/python3.7/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/html/parser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/html/parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# < + letter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/html/parser.py\u001b[0m in \u001b[0;36mparse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_startendtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDATA_CONTENT_ELEMENTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cdata_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ny-warn-scraper-49ZA02KO/lib/python3.7/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mattrvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\"\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m#print \"START\", name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0msourceline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msourcepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         tag = self.soup.handle_starttag(\n\u001b[1;32m    122\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msourceline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msourceline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/_markupbase.py\u001b[0m in \u001b[0;36mgetpos\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mgetpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;34m\"\"\"Return current line number and offset.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# make an array called 'results'\n",
    "results = []\n",
    "# loop through the rows using a for loop. each row here is a company\n",
    "for row in rows:\n",
    "    # grab the anchor tag (the link tag) in the row and then grab the href attribute from the tag\n",
    "    a = row.find(\"a\")['href']\n",
    "    \n",
    "    # concatenate the root url from above with this href attribute and assign to a variable called 'company_url'\n",
    "    company_url = f'{url}{a}'\n",
    "    #print(company_url)\n",
    "    \n",
    "    # make a get request to the company url assign the response to a variable called 'company_response'\n",
    "    company_response = requests.get(company_url, headers=headers)\n",
    "    \n",
    "    # parse the response text and assign output to a variable called 'company_soup'\n",
    "    company_soup = BeautifulSoup(company_response.text, 'html.parser')\n",
    "\n",
    "    # grab the first table on the page\n",
    "    company_table = company_soup.find(\"table\")\n",
    "\n",
    "    # unwrap all of the spans\n",
    "    \n",
    "    # loop through all of the p tags\n",
    "    paragraphs = company_table.find_all(\"p\")\n",
    "    for p in paragraphs:\n",
    "        # grab all of the values we want\n",
    "        text = p.get_text('\\n')\n",
    "        if 'Date of Notice:' in text:\n",
    "            notice_date = text.split(\":\")[1].strip().split('\\n')[0].strip().replace(',', '').replace(';', '')\n",
    "            #print(notice_date)\n",
    "        elif 'Reason Stated for Filing:' in text:\n",
    "            reason = text.split(\":\")[1].strip()\n",
    "            #print(reason)\n",
    "        elif 'Company:' in text:\n",
    "            split_company = text.split(\"\\n\")\n",
    "            #print(split_company)\n",
    "            company = split_company[1].strip()\n",
    "            address = ''.join(split_company[2:])\n",
    "#             print(company)\n",
    "#             print(address)\n",
    "        elif 'County:' in text:\n",
    "            county = f'{text.split(\":\")[1].strip().split(\"|\")[0].strip()} County'\n",
    "            #print(county)\n",
    "        elif 'Phone:' in text:\n",
    "            phone = text.split(\":\")[1].strip()\n",
    "            #print(phone)\n",
    "        elif 'Business Type:' in text:\n",
    "            business_type = text.split(\":\")[1].strip().replace('Restaurants', 'Restaurant')\n",
    "            #print(business_type)\n",
    "        elif 'Number Affected:' in text:\n",
    "            if '-----' in text:\n",
    "                affected = ''\n",
    "            else:\n",
    "                affected = text.split(\":\")[1].strip().split(\" \")[0].strip().split('\\n')[0].strip()\n",
    "            #print(affected)\n",
    "        elif 'Total Employees:' in text:\n",
    "            if '-----' in text:\n",
    "                total_employees = ''\n",
    "            else:\n",
    "                total_employees = text.split(\":\")[1].strip().split(\" \")[0].strip().replace(',', '')\n",
    "                #print(total_employees)\n",
    "        elif 'Layoff Date:' in text:\n",
    "            #print(text)\n",
    "            layoff_date = text.split(\":\")[1].strip().split(\" \")[0].strip().split(\" \")[0].strip()\n",
    "            #print(layoff_date)\n",
    "        elif ('Reason for Dislocation:' in text):\n",
    "            dislocation = text.split(\":\")[1].strip()\n",
    "            #print(dislocation)\n",
    "        elif ('Union:' in text):\n",
    "            union = text.split(\":\")[1].strip()\n",
    "            #print(union)\n",
    "        elif ('Classification:' in text):\n",
    "            classification = text.split(\":\")[1].strip()\n",
    "            #print(classification)\n",
    "            \n",
    "    # store values in a result object\n",
    "    result = {\n",
    "        'notice_date': notice_date,\n",
    "        'reason': reason,\n",
    "        'company': company,\n",
    "        'address': address,\n",
    "        'county': county,\n",
    "        'phone': phone,\n",
    "        'business_type': business_type,\n",
    "        'affected': affected,\n",
    "        'total_employees': total_employees,\n",
    "        'layoff_date': layoff_date,\n",
    "        'dislocation': dislocation,\n",
    "        'union': union,\n",
    "        'classification': classification\n",
    "     }\n",
    "    \n",
    "    # append result object to results\n",
    "    results.append(result)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap results in a dataframe\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3/19/2020', '5/29/2020', '6/1/2020', '3/18/2020', '3/30/2020',\n",
       "       '3/12/2020', '3/27/2020', '4/24/2020', '4/16/2020', '3/20/2020',\n",
       "       '4/3/2020', '6/30/2020', '4/23/2020', '3/16/2020', '3/17/2020',\n",
       "       '4/4/2020', '4/8/2020', '4/22/2020', '3/24/2020', '4/13/2020',\n",
       "       '4/10/2020', 'Furloughs', '3/22/2020', '3/23/2020', 'Separation',\n",
       "       '3/29/2020', '3/25/2020', 'Separations', '32', 'Layoffs',\n",
       "       '7/30/2020', '4/25/2020', '4/1/2020', '7/19/2020', '6/19/2020',\n",
       "       '7/3/2020', '4/20/2020', '3/31/2020', '4/14/2020', '3/28/2020',\n",
       "       '72', 'The', '51', '86', '88', '37', 'Nine', '4/6/2020',\n",
       "       '4/30/2020', '(21)', '(27)', 'March', '30', '18', '14', 'Seven',\n",
       "       '4/2/2020', '3/21/2020', '356', '34', '330', '69', '52', '87',\n",
       "       '81', '-----', '4/7/2020', '48', '3/15/2020', '3/26/2020',\n",
       "       '3/10/2020', '4/12/2020', '362', '5/1/2020', '3/13/2020',\n",
       "       '4/5/2020', '3/19/2020,', '7/12/2020', '4/11/2020', '6/26/2020',\n",
       "       '4/1/2020,', '7/1/2020', '287', 'A', '146', '3/14/2020',\n",
       "       '3/6/2020', 'May', '6/21/2020', '6/24/2020', '2/23/2020',\n",
       "       '3/11/2020', 'Close', '', '6/12/2020', 'June', 'First',\n",
       "       '6/17/2020', 'To', '7/31/2020', '6/3/2020', '6/14/2020',\n",
       "       '5/31/2020', 'December', 'Employee', 'Employment', '2/29/2020',\n",
       "       '5/22/2020', 'April', 'Separtions', 'Employees', '4/27/2020',\n",
       "       \"Macy's\", 'Beginning', '1/12/2020'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 1237\n",
    "df['layoff_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataframe to a csv\n",
    "df.to_csv('../data/warn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
