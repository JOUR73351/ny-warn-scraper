{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the import keyword to import pandas, requests, and bs4 modules\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the NY WARN notice url to a variable\n",
    "url = \"https://labor.ny.gov/app/warn/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define headers\n",
    "headers = {'accept-encoding': 'deflate', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a get request to the url using the requests library and assign the response to a variable called 'response'\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out status code of response to confirm that your request worked\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse the response text using Beautiful Soup's html parser and assign output to a variable called 'soup'\n",
    "# response.text\n",
    "type(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the first table on the page and assign it to a variable called 'table'\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all rows from the table and assign to a variable called 'rows'\n",
    "table = soup.find(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the number of rows â€” this is how many WARN notices there were in 2020\n",
    "rows = soup.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/4/2020\n",
      "5/4/2020\n",
      "4/30/2020\n",
      "5/4/2020\n",
      "['Date of Notice', ' 1/24/2020 \\nAmendment', ' 4/29/2020']\n",
      "4/29/2020\n",
      "['Date of Notice', ' 1/24/2020 \\nAmendment', ' 4/29/2020']\n",
      "4/29/2020\n",
      "repeated event number\n",
      "https://labor.ny.gov/app/warn/details.asp?id=8352\n",
      "4/17/2020\n",
      "5/1/2020\n",
      "4/14/2020\n",
      "4/30/2020\n",
      "4/21/2020\n",
      "4/27/2020\n",
      "4/27/2020\n",
      "4/27/2020\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-55f3d7019d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# parse the response text and assign output to a variable called 'company_soup'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcompany_soup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# grab the first table on the page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ny-warn-scraper-49ZA02KO/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ny-warn-scraper-49ZA02KO/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ny-warn-scraper-49ZA02KO/lib/python3.7/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/html/parser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/html/parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# < + letter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/html/parser.py\u001b[0m in \u001b[0;36mparse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_startendtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDATA_CONTENT_ELEMENTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_cdata_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ny-warn-scraper-49ZA02KO/lib/python3.7/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[1;32m    121\u001b[0m         tag = self.soup.handle_starttag(\n\u001b[1;32m    122\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msourceline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msourceline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0msourcepos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msourcepos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_empty_element\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhandle_empty_element\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ny-warn-scraper-49ZA02KO/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mhandle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \"\"\"\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# print \"Start tag %s: %s\" % (name, attrs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         if (self.parse_only and len(self.tagStack) <= 1\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ny-warn-scraper-49ZA02KO/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mendData\u001b[0;34m(self, containerClass)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontainerClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_was_parsed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/ny-warn-scraper-49ZA02KO/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0mknown_xml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \"\"\"Create a new NavigableString.\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# make an array called 'results'\n",
    "results = []\n",
    "event_numbers = set()\n",
    "# loop through the rows using a for loop. each row here is a company\n",
    "for row in rows:\n",
    "    # grab the anchor tag (the link tag) in the row and then grab the href attribute from the tag\n",
    "    a = row.find(\"a\")['href']\n",
    "    \n",
    "    # concatenate the root url from above with this href attribute and assign to a variable called 'company_url'\n",
    "    company_url = f'{url}{a}'\n",
    "    #company_url = 'https://labor.ny.gov/app/warn/details.asp?id=7341'\n",
    "    #print(company_url)\n",
    "    \n",
    "    # make a get request to the company url assign the response to a variable called 'company_response'\n",
    "    company_response = requests.get(company_url, headers=headers)\n",
    "    \n",
    "    # parse the response text and assign output to a variable called 'company_soup'\n",
    "    company_soup = BeautifulSoup(company_response.text, 'html.parser')\n",
    "\n",
    "    # grab the first table on the page\n",
    "    company_table = company_soup.find(\"table\")\n",
    "\n",
    "    # unwrap all of the spans\n",
    "    \n",
    "    # loop through all of the p tags\n",
    "    paragraphs = company_table.find_all(\"p\")\n",
    "    skip = False\n",
    "    for p in paragraphs:\n",
    "        # grab all of the values we want\n",
    "        text = p.get_text('\\n').replace('\\xa0', '')\n",
    "        if 'Date of Notice:' in text:\n",
    "            split_notice_date = text.split(\":\")\n",
    "            #print(split_notice_date)\n",
    "            if len(split_notice_date) == 3:\n",
    "                print(split_notice_date)\n",
    "                notice_date = split_notice_date[2].strip().split()[0].strip()\n",
    "            else:\n",
    "                notice_date = text.split(\":\")[1].strip().split()[0].strip().replace(',', '').replace(';', '')\n",
    "            print(notice_date)\n",
    "        elif 'Event Number:' in text:\n",
    "            event_number = text.split(\":\")[1].strip()\n",
    "            if event_number in event_numbers:\n",
    "                print('repeated event number')\n",
    "                print(company_url)\n",
    "                skip = True\n",
    "                break\n",
    "            else:\n",
    "                event_numbers.add(event_number)\n",
    "        elif 'Reason Stated for Filing:' in text:\n",
    "            reason = text.split(\":\")[1].strip()\n",
    "            #print(reason)\n",
    "        elif 'Company:' in text:\n",
    "            split_company = [x.strip() for x in text.split('\\n')]\n",
    "            #print(split_company)\n",
    "            company = split_company[1].strip()\n",
    "            address = ''.join(split_company[2:])\n",
    "#             print(company)\n",
    "#             print(address)\n",
    "        elif 'County:' in text:\n",
    "            county = f'{text.split(\":\")[1].strip().split(\"|\")[0].strip()} County'\n",
    "            #print(county)\n",
    "        elif 'Phone:' in text:\n",
    "            phone = text.split(\":\")[1].strip()\n",
    "            #print(phone)\n",
    "        elif 'Business Type:' in text:\n",
    "            business_type = text.split(\":\")[1].strip().replace('Restaurants', 'Restaurant')\n",
    "            #print(business_type)\n",
    "        elif 'Number Affected:' in text:\n",
    "            affected = text.split(\":\")[1].strip().split(\" \")[0].strip().split('\\n')[0].strip().replace(',', '').replace('(', '')\n",
    "            if affected in ['------', '-----', '----']:\n",
    "                affected = 0\n",
    "        elif 'Total Employees:' in text:\n",
    "            total_employees = text.split(\":\")[1].strip().split(\" \")[0].strip().replace(',', '')\n",
    "            if total_employees in ['------', '-----', '----']:\n",
    "                total_employees = 0\n",
    "            #print(total_employees)\n",
    "        elif 'Layoff Date:' in text:\n",
    "            #print(text)\n",
    "            layoff_date = text.split(\":\")[1].strip().split(\" \")[0].strip().split(\" \")[0].strip()\n",
    "            #print(layoff_date)\n",
    "        elif ('Reason for Dislocation:' in text):\n",
    "            dislocation = text.split(\":\")[1].strip()\n",
    "            #print(dislocation)\n",
    "        elif ('Union:' in text):\n",
    "            union = text.split(\":\")[1].strip()\n",
    "            #print(union)\n",
    "        elif ('Classification:' in text):\n",
    "            classification = text.split(\":\")[1].strip()\n",
    "            #print(classification)\n",
    "            \n",
    "    # store values in a result object\n",
    "    if not skip:\n",
    "        result = {\n",
    "            'notice_date': notice_date,\n",
    "            'event_number': event_number,\n",
    "            'reason': reason,\n",
    "            'company': company,\n",
    "            'address': address,\n",
    "            'county': county,\n",
    "            'phone': phone,\n",
    "            'business_type': business_type,\n",
    "            'affected': affected,\n",
    "            'total_employees': total_employees,\n",
    "            'layoff_date': layoff_date,\n",
    "            'dislocation': dislocation,\n",
    "            'union': union,\n",
    "            'classification': classification\n",
    "         }\n",
    "\n",
    "        # append result object to results\n",
    "        results.append(result)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1213, 14)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrap results in a dataframe\n",
    "df = pd.DataFrame(results)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['174', '260', '239', '289', '154', '447', '393', '696', '274',\n",
       "       '97', '93', '18', '169', '4', '52', '14', '53', '192', '38', '8',\n",
       "       '21', '317', '39', '29', '196', '22', '36', '140', '113', '218',\n",
       "       '131', '142', '35', '149', '359', '132', '209', '814', '222',\n",
       "       '146', '1004', '689', '507', '44', '81', '64', '65', '54', '32',\n",
       "       '178', '6', '107', '28', '70', '68', '25', '85', '99', '124', '24',\n",
       "       '120', '84', '17', '60', '157', '75', nan, '91', '58', '15', '47',\n",
       "       '49', '41', '210', '34', '74', '40', '16', '61', '62', '48', '456',\n",
       "       '133', '2', '116', '119', '27', '23', '678', '459', '19', '66',\n",
       "       '46', '33', '165', '429', '95', '104', '20', '397', '55', '115',\n",
       "       '357', '67', '76', '110', '103', '3', '12', '26', '89', '1', '204',\n",
       "       '7', '13', '185', '63', '545', '90', '280', '57', '9', '72', '5',\n",
       "       '42', '87', '128', '101', '167', '77', '159', '247', '717', '251',\n",
       "       '69', '10', '30', '50', '126', '78', '83', '86', '71', '37',\n",
       "       '1166', '401', '244', '112', '579', '51', '102', '173', '31', '80',\n",
       "       '376', '197', '353', '268', '410', '176', '59', '82', '206', '100',\n",
       "       '96', '141', '214', '129', '105', '94', '92', '183', '172', '106',\n",
       "       '43', '195', '163', '226', '211', '73', '554', '158', '11', '121',\n",
       "       '147', '45', '342', '590', '175', '139', '155', '315', '144',\n",
       "       '114', '111', '161', '300', '79', '136', '108', '125', '259',\n",
       "       '258', '170', '130', '135', '123', '177', '212', '314', '415',\n",
       "       '311', '184', '883', '137', '189', '164', '236', '700', '143',\n",
       "       '145', '118', '272', '109', '250', '275', '324', '310', '230',\n",
       "       '180', '563', '273', '416', '331', '290', '395', '335', '181',\n",
       "       '285', '216', '372', '179', '240', '150', '316', '134', '238',\n",
       "       '117', '207', '241', '297', '56', '127', '122', '762', '282',\n",
       "       '577', '683', '138', '246', '265', '202', '669', '88', '1321',\n",
       "       '98', '231', '292', '278', '198', '225', '340', '744', '375',\n",
       "       '221', '201', '160'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['affected'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataframe to a csv\n",
    "df.to_csv('../data/warn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
